{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_label_idx(labels, targets, shots=5, test=False):\n",
    "    \"\"\"\n",
    "    Get the indices of labels that are included in targets.\n",
    "    :param labels: array of labels\n",
    "    :param targets: list/tuple of target labels\n",
    "    :return: list with indices of target labels\n",
    "    \"\"\"\n",
    "    final_list = []\n",
    "    \n",
    "    for t in targets:\n",
    "        if test:\n",
    "            final_list += np.argwhere(np.isin(labels, t)).flatten().tolist()\n",
    "        else:\n",
    "            final_list += np.argwhere(np.isin(labels, t)).flatten().tolist()[:shots]\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert labels [5,6,7,8,9] to [0,1,2,3,4]\n",
    "def convert_label(x):\n",
    "\n",
    "    if x >= 5:\n",
    "        return x-5\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from PIL import Image\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MNIST_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, root: str, normal_class=[5,6,7,8,9], shots=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = root\n",
    "        self.n_classes = 2  # 0: normal, 1: outlier\n",
    "        self.normal_classes = tuple(normal_class)\n",
    "        self.outlier_classes = list(range(0, 10))\n",
    "        self.outlier_classes = [item for item in self.outlier_classes if item not in self.normal_classes]\n",
    "#         self.outlier_classes.remove(normal_class)\n",
    "        print(\"classes: \", self.normal_classes)\n",
    "#         # MNIST preprocessing: GCN (with L1 norm) and min-max feature scaling to [0,1]\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "#         target_transform = transforms.Lambda(lambda x: int(x in self.normal_classes))\n",
    "        \n",
    "        target_transform = transforms.Lambda(lambda x: convert_label(x))\n",
    "        train_set = MyMNIST(root=self.root, train=True, download=True,\n",
    "                            transform=transform, target_transform=target_transform)\n",
    "        # Subset train_set to normal class\n",
    "        train_idx_normal = get_target_label_idx(train_set.train_labels.clone().data.cpu().numpy(), self.normal_classes, shots=shots)\n",
    "        self.train_set = Subset(train_set, train_idx_normal)\n",
    "\n",
    "        test_set = MyMNIST(root=self.root, train=False, download=True,\n",
    "                                transform=transform, target_transform=target_transform)\n",
    "        \n",
    "        test_idx_normal = get_target_label_idx(test_set.test_labels.clone().data.cpu().numpy(), self.normal_classes, test=True)\n",
    "        self.test_set = Subset(test_set, test_idx_normal)\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "class MyMNIST(MNIST):\n",
    "    \"\"\"Torchvision MNIST class with patch of __getitem__ method to also return the index of a data sample.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyMNIST, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Override the original method of the MNIST class.\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            triple: (image, target, index) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index  # only line changed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" LeNet architecture implementation\n",
    "\"\"\"\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                \n",
    "                for data in train_loader:\n",
    "                    inputs, labels, idx = data\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        outputs = model(inputs)\n",
    "                        \n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "#                         print(preds, labels)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "                scheduler.step()\n",
    "                \n",
    "                epoch_loss = running_loss / train_size\n",
    "                epoch_acc = running_corrects.double() / train_size\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format('Train', epoch_loss, epoch_acc))\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                \n",
    "                for data in test_loader:\n",
    "                    inputs, labels, idx = data\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        \n",
    "                        loss = criterion(outputs, labels)\n",
    "                \n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                epoch_loss = running_loss / test_size\n",
    "                epoch_acc = running_corrects.double() / test_size\n",
    "                \n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format('Val', epoch_loss, epoch_acc))\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  (5, 6, 7, 8, 9)\n",
      "Labels:  tensor([3, 4, 1, 2, 0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mninst_dataset = MNIST_Dataset(root='data/', shots=5)\n",
    "train_loader = DataLoader(mninst_dataset.train_set, batch_size=5, shuffle=True, num_workers=0)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels, idx = dataiter.next()\n",
    "print(\"Labels: \", labels)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  (5, 6, 7, 8, 9)\n",
      "Epoch 0/199\n",
      "----------\n",
      "Train Loss: 1.6107 Acc: 0.2000\n",
      "Val Loss: 1.6073 Acc: 0.2076\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "Train Loss: 1.6085 Acc: 0.2022\n",
      "Val Loss: 1.6058 Acc: 0.2181\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "Train Loss: 1.6065 Acc: 0.2630\n",
      "Val Loss: 1.6040 Acc: 0.3145\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "Train Loss: 1.6046 Acc: 0.3208\n",
      "Val Loss: 1.6023 Acc: 0.3573\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "Train Loss: 1.6025 Acc: 0.3546\n",
      "Val Loss: 1.6001 Acc: 0.3919\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "Train Loss: 1.5999 Acc: 0.3922\n",
      "Val Loss: 1.5972 Acc: 0.4392\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "Train Loss: 1.5962 Acc: 0.4306\n",
      "Val Loss: 1.5927 Acc: 0.5106\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "Train Loss: 1.5908 Acc: 0.4414\n",
      "Val Loss: 1.5860 Acc: 0.5377\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "Train Loss: 1.5824 Acc: 0.5258\n",
      "Val Loss: 1.5750 Acc: 0.5937\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "Train Loss: 1.5677 Acc: 0.6112\n",
      "Val Loss: 1.5549 Acc: 0.6075\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "Train Loss: 1.5386 Acc: 0.5924\n",
      "Val Loss: 1.5122 Acc: 0.6151\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "Train Loss: 1.4693 Acc: 0.6186\n",
      "Val Loss: 1.3989 Acc: 0.6030\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "Train Loss: 1.2567 Acc: 0.7024\n",
      "Val Loss: 1.0505 Acc: 0.7186\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "Train Loss: 0.8359 Acc: 0.8008\n",
      "Val Loss: 0.6613 Acc: 0.8369\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "Train Loss: 0.5357 Acc: 0.8510\n",
      "Val Loss: 0.4732 Acc: 0.8622\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "Train Loss: 0.3961 Acc: 0.8788\n",
      "Val Loss: 0.3700 Acc: 0.8922\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "Train Loss: 0.3363 Acc: 0.8994\n",
      "Val Loss: 0.3486 Acc: 0.8976\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "Train Loss: 0.3256 Acc: 0.9028\n",
      "Val Loss: 0.3427 Acc: 0.8978\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "Train Loss: 0.3198 Acc: 0.9028\n",
      "Val Loss: 0.3338 Acc: 0.9008\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "Train Loss: 0.3139 Acc: 0.9040\n",
      "Val Loss: 0.3277 Acc: 0.9023\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "Train Loss: 0.3081 Acc: 0.9052\n",
      "Val Loss: 0.3224 Acc: 0.9048\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "Train Loss: 0.3021 Acc: 0.9064\n",
      "Val Loss: 0.3183 Acc: 0.9043\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "Train Loss: 0.2972 Acc: 0.9072\n",
      "Val Loss: 0.3143 Acc: 0.9064\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "Train Loss: 0.2925 Acc: 0.9094\n",
      "Val Loss: 0.3076 Acc: 0.9089\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "Train Loss: 0.2876 Acc: 0.9108\n",
      "Val Loss: 0.3024 Acc: 0.9107\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "Train Loss: 0.2828 Acc: 0.9128\n",
      "Val Loss: 0.2978 Acc: 0.9099\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "Train Loss: 0.2789 Acc: 0.9140\n",
      "Val Loss: 0.2949 Acc: 0.9120\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "Train Loss: 0.2752 Acc: 0.9128\n",
      "Val Loss: 0.2922 Acc: 0.9122\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "Train Loss: 0.2717 Acc: 0.9154\n",
      "Val Loss: 0.2868 Acc: 0.9138\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "Train Loss: 0.2681 Acc: 0.9140\n",
      "Val Loss: 0.2848 Acc: 0.9128\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "Train Loss: 0.2643 Acc: 0.9156\n",
      "Val Loss: 0.2797 Acc: 0.9150\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "Train Loss: 0.2610 Acc: 0.9176\n",
      "Val Loss: 0.2791 Acc: 0.9154\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "Train Loss: 0.2605 Acc: 0.9178\n",
      "Val Loss: 0.2789 Acc: 0.9159\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "Train Loss: 0.2603 Acc: 0.9176\n",
      "Val Loss: 0.2783 Acc: 0.9161\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "Train Loss: 0.2599 Acc: 0.9186\n",
      "Val Loss: 0.2781 Acc: 0.9159\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "Train Loss: 0.2597 Acc: 0.9186\n",
      "Val Loss: 0.2778 Acc: 0.9159\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "Train Loss: 0.2594 Acc: 0.9172\n",
      "Val Loss: 0.2775 Acc: 0.9157\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "Train Loss: 0.2590 Acc: 0.9172\n",
      "Val Loss: 0.2774 Acc: 0.9154\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "Train Loss: 0.2587 Acc: 0.9178\n",
      "Val Loss: 0.2770 Acc: 0.9154\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "Train Loss: 0.2583 Acc: 0.9178\n",
      "Val Loss: 0.2765 Acc: 0.9157\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "Train Loss: 0.2579 Acc: 0.9184\n",
      "Val Loss: 0.2764 Acc: 0.9154\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "Train Loss: 0.2577 Acc: 0.9182\n",
      "Val Loss: 0.2759 Acc: 0.9157\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "Train Loss: 0.2574 Acc: 0.9184\n",
      "Val Loss: 0.2756 Acc: 0.9159\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "Train Loss: 0.2571 Acc: 0.9190\n",
      "Val Loss: 0.2754 Acc: 0.9154\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "Train Loss: 0.2568 Acc: 0.9190\n",
      "Val Loss: 0.2749 Acc: 0.9159\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "Train Loss: 0.2565 Acc: 0.9188\n",
      "Val Loss: 0.2746 Acc: 0.9161\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "Train Loss: 0.2560 Acc: 0.9190\n",
      "Val Loss: 0.2746 Acc: 0.9161\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "Train Loss: 0.2560 Acc: 0.9192\n",
      "Val Loss: 0.2745 Acc: 0.9161\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "Train Loss: 0.2560 Acc: 0.9188\n",
      "Val Loss: 0.2745 Acc: 0.9161\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "Train Loss: 0.2560 Acc: 0.9190\n",
      "Val Loss: 0.2745 Acc: 0.9161\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "Train Loss: 0.2559 Acc: 0.9190\n",
      "Val Loss: 0.2744 Acc: 0.9161\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "Train Loss: 0.2559 Acc: 0.9194\n",
      "Val Loss: 0.2744 Acc: 0.9161\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "Train Loss: 0.2559 Acc: 0.9192\n",
      "Val Loss: 0.2744 Acc: 0.9161\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "Train Loss: 0.2558 Acc: 0.9192\n",
      "Val Loss: 0.2744 Acc: 0.9161\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "Train Loss: 0.2558 Acc: 0.9192\n",
      "Val Loss: 0.2744 Acc: 0.9159\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "Train Loss: 0.2558 Acc: 0.9192\n",
      "Val Loss: 0.2744 Acc: 0.9159\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "Train Loss: 0.2557 Acc: 0.9194\n",
      "Val Loss: 0.2743 Acc: 0.9159\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "Train Loss: 0.2557 Acc: 0.9194\n",
      "Val Loss: 0.2743 Acc: 0.9159\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "Train Loss: 0.2557 Acc: 0.9194\n",
      "Val Loss: 0.2743 Acc: 0.9159\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "Train Loss: 0.2556 Acc: 0.9192\n",
      "Val Loss: 0.2743 Acc: 0.9159\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "Train Loss: 0.2556 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "Train Loss: 0.2556 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "Train Loss: 0.2556 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "Train Loss: 0.2556 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.9194\n",
      "Val Loss: 0.2742 Acc: 0.9159\n",
      "\n",
      "Training complete in 5m 14s\n",
      "Best val Acc: 0.916067\n"
     ]
    }
   ],
   "source": [
    "# pretraining model\n",
    "mninst_dataset = MNIST_Dataset(root='data/', normal_class=[5,6,7,8,9] ,shots=1000)\n",
    "train_loader = DataLoader(mninst_dataset.train_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(mninst_dataset.test_set, batch_size=200, shuffle=True, num_workers=0)\n",
    "train_size =  len(mninst_dataset.train_set)\n",
    "test_size = len(mninst_dataset.test_set)\n",
    "\n",
    "net = LeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 15 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=15, gamma=0.1)\n",
    "\n",
    "best_net, best_acc = train_model(net, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haal01/Desktop/Projects/deep-svdd-env/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type LeNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Saving the pretrained model\n",
    "torch.save(best_net, 'LeNet_5_class_pretrained_model.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  (0, 1, 2, 3, 4)\n",
      "Epoch 0/19\n",
      "----------\n",
      "Train Loss: 2.5677 Acc: 0.3600\n",
      "Val Loss: 3.0720 Acc: 0.3966\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "Train Loss: 1.8615 Acc: 0.4800\n",
      "Val Loss: 2.2230 Acc: 0.4312\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "Train Loss: 1.6933 Acc: 0.4800\n",
      "Val Loss: 2.3014 Acc: 0.5633\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "Train Loss: 1.2780 Acc: 0.6800\n",
      "Val Loss: 1.3240 Acc: 0.5357\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "Train Loss: 0.8697 Acc: 0.6400\n",
      "Val Loss: 1.6447 Acc: 0.6188\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "Train Loss: 0.6996 Acc: 0.7200\n",
      "Val Loss: 1.0363 Acc: 0.6659\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "Train Loss: 0.5100 Acc: 0.8400\n",
      "Val Loss: 0.9158 Acc: 0.7060\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "Train Loss: 0.4611 Acc: 0.8800\n",
      "Val Loss: 0.9403 Acc: 0.6996\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "Train Loss: 0.3716 Acc: 0.8400\n",
      "Val Loss: 0.8874 Acc: 0.7128\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "Train Loss: 0.3307 Acc: 0.8400\n",
      "Val Loss: 0.8486 Acc: 0.7225\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "Train Loss: 0.3082 Acc: 0.9200\n",
      "Val Loss: 0.8304 Acc: 0.7297\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "Train Loss: 0.3049 Acc: 0.9200\n",
      "Val Loss: 0.8210 Acc: 0.7313\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "Train Loss: 0.3003 Acc: 0.9200\n",
      "Val Loss: 0.8180 Acc: 0.7340\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "Train Loss: 0.2942 Acc: 0.9600\n",
      "Val Loss: 0.8174 Acc: 0.7342\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "Train Loss: 0.2882 Acc: 0.9200\n",
      "Val Loss: 0.8178 Acc: 0.7320\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "Train Loss: 0.2840 Acc: 0.9200\n",
      "Val Loss: 0.8181 Acc: 0.7320\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "Train Loss: 0.2835 Acc: 0.9200\n",
      "Val Loss: 0.8182 Acc: 0.7322\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "Train Loss: 0.2828 Acc: 0.9200\n",
      "Val Loss: 0.8183 Acc: 0.7322\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "Train Loss: 0.2824 Acc: 0.9200\n",
      "Val Loss: 0.8182 Acc: 0.7324\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "Train Loss: 0.2819 Acc: 0.9200\n",
      "Val Loss: 0.8184 Acc: 0.7320\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.734190\n",
      "classes:  (0, 1, 2, 3, 4)\n",
      "Epoch 0/19\n",
      "----------\n",
      "Train Loss: 2.8119 Acc: 0.4200\n",
      "Val Loss: 2.7926 Acc: 0.4625\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "Train Loss: 2.1892 Acc: 0.4000\n",
      "Val Loss: 1.4117 Acc: 0.5505\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "Train Loss: 1.1225 Acc: 0.6000\n",
      "Val Loss: 0.9949 Acc: 0.6898\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "Train Loss: 0.8469 Acc: 0.7800\n",
      "Val Loss: 0.8703 Acc: 0.6980\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "Train Loss: 0.6967 Acc: 0.8400\n",
      "Val Loss: 0.8217 Acc: 0.7309\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "Train Loss: 0.5629 Acc: 0.8600\n",
      "Val Loss: 0.6701 Acc: 0.7770\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "Train Loss: 0.4936 Acc: 0.8200\n",
      "Val Loss: 0.6418 Acc: 0.7764\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "Train Loss: 0.3834 Acc: 0.9200\n",
      "Val Loss: 0.5616 Acc: 0.8007\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "Train Loss: 0.3257 Acc: 0.9200\n",
      "Val Loss: 0.5466 Acc: 0.8087\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "Train Loss: 0.3187 Acc: 0.9400\n",
      "Val Loss: 0.5405 Acc: 0.8118\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "Train Loss: 0.3122 Acc: 0.9400\n",
      "Val Loss: 0.5361 Acc: 0.8134\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "Train Loss: 0.3057 Acc: 0.9400\n",
      "Val Loss: 0.5354 Acc: 0.8136\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "Train Loss: 0.3035 Acc: 0.9400\n",
      "Val Loss: 0.5351 Acc: 0.8142\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "Train Loss: 0.2955 Acc: 0.9400\n",
      "Val Loss: 0.5311 Acc: 0.8155\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "Train Loss: 0.2894 Acc: 0.9400\n",
      "Val Loss: 0.5250 Acc: 0.8163\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "Train Loss: 0.2850 Acc: 0.9400\n",
      "Val Loss: 0.5248 Acc: 0.8163\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "Train Loss: 0.2847 Acc: 0.9400\n",
      "Val Loss: 0.5236 Acc: 0.8167\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "Train Loss: 0.2840 Acc: 0.9400\n",
      "Val Loss: 0.5235 Acc: 0.8169\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "Train Loss: 0.2835 Acc: 0.9400\n",
      "Val Loss: 0.5230 Acc: 0.8167\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "Train Loss: 0.2829 Acc: 0.9400\n",
      "Val Loss: 0.5228 Acc: 0.8175\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.817474\n",
      "classes:  (0, 1, 2, 3, 4)\n",
      "Epoch 0/19\n",
      "----------\n",
      "Train Loss: 2.6193 Acc: 0.4400\n",
      "Val Loss: 2.5053 Acc: 0.4711\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "Train Loss: 1.2432 Acc: 0.5333\n",
      "Val Loss: 0.8982 Acc: 0.7408\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "Train Loss: 0.7575 Acc: 0.8133\n",
      "Val Loss: 0.7859 Acc: 0.7229\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "Train Loss: 0.5384 Acc: 0.8133\n",
      "Val Loss: 0.5776 Acc: 0.8099\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "Train Loss: 0.3670 Acc: 0.9067\n",
      "Val Loss: 0.5048 Acc: 0.8268\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "Train Loss: 0.2951 Acc: 0.9067\n",
      "Val Loss: 0.4406 Acc: 0.8484\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "Train Loss: 0.2369 Acc: 0.9333\n",
      "Val Loss: 0.5375 Acc: 0.8054\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "Train Loss: 0.2317 Acc: 0.9467\n",
      "Val Loss: 0.3420 Acc: 0.8838\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "Train Loss: 0.1597 Acc: 0.9600\n",
      "Val Loss: 0.3487 Acc: 0.8815\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "Train Loss: 0.1438 Acc: 0.9733\n",
      "Val Loss: 0.3637 Acc: 0.8749\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "Train Loss: 0.1419 Acc: 0.9867\n",
      "Val Loss: 0.3757 Acc: 0.8714\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "Train Loss: 0.1364 Acc: 1.0000\n",
      "Val Loss: 0.3761 Acc: 0.8712\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "Train Loss: 0.1347 Acc: 1.0000\n",
      "Val Loss: 0.3648 Acc: 0.8729\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "Train Loss: 0.1322 Acc: 1.0000\n",
      "Val Loss: 0.3660 Acc: 0.8747\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "Train Loss: 0.1286 Acc: 1.0000\n",
      "Val Loss: 0.3610 Acc: 0.8759\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "Train Loss: 0.1248 Acc: 1.0000\n",
      "Val Loss: 0.3609 Acc: 0.8759\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "Train Loss: 0.1247 Acc: 1.0000\n",
      "Val Loss: 0.3604 Acc: 0.8762\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "Train Loss: 0.1245 Acc: 1.0000\n",
      "Val Loss: 0.3612 Acc: 0.8768\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "Train Loss: 0.1242 Acc: 1.0000\n",
      "Val Loss: 0.3606 Acc: 0.8766\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "Train Loss: 0.1241 Acc: 1.0000\n",
      "Val Loss: 0.3605 Acc: 0.8762\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.883830\n",
      "classes:  (0, 1, 2, 3, 4)\n",
      "Epoch 0/19\n",
      "----------\n",
      "Train Loss: 2.6741 Acc: 0.5100\n",
      "Val Loss: 1.5513 Acc: 0.5435\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "Train Loss: 1.0867 Acc: 0.6900\n",
      "Val Loss: 1.0223 Acc: 0.6914\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "Train Loss: 0.7619 Acc: 0.7700\n",
      "Val Loss: 0.8613 Acc: 0.7007\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "Train Loss: 0.5489 Acc: 0.8300\n",
      "Val Loss: 0.6433 Acc: 0.7949\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "Train Loss: 0.4146 Acc: 0.9100\n",
      "Val Loss: 0.5308 Acc: 0.8093\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "Train Loss: 0.2916 Acc: 0.9000\n",
      "Val Loss: 0.4283 Acc: 0.8609\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "Train Loss: 0.2526 Acc: 0.8900\n",
      "Val Loss: 0.4193 Acc: 0.8517\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "Train Loss: 0.2398 Acc: 0.9200\n",
      "Val Loss: 0.4749 Acc: 0.8346\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "Train Loss: 0.1691 Acc: 0.9400\n",
      "Val Loss: 0.3747 Acc: 0.8766\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "Train Loss: 0.1309 Acc: 0.9800\n",
      "Val Loss: 0.3509 Acc: 0.8827\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "Train Loss: 0.1271 Acc: 0.9800\n",
      "Val Loss: 0.3480 Acc: 0.8829\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "Train Loss: 0.1247 Acc: 0.9800\n",
      "Val Loss: 0.3496 Acc: 0.8813\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "Train Loss: 0.1230 Acc: 0.9800\n",
      "Val Loss: 0.3446 Acc: 0.8840\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "Train Loss: 0.1175 Acc: 0.9900\n",
      "Val Loss: 0.3478 Acc: 0.8834\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "Train Loss: 0.1158 Acc: 0.9900\n",
      "Val Loss: 0.3491 Acc: 0.8825\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "Train Loss: 0.1122 Acc: 0.9900\n",
      "Val Loss: 0.3485 Acc: 0.8823\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "Train Loss: 0.1119 Acc: 0.9900\n",
      "Val Loss: 0.3480 Acc: 0.8825\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "Train Loss: 0.1117 Acc: 0.9900\n",
      "Val Loss: 0.3471 Acc: 0.8827\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "Train Loss: 0.1114 Acc: 0.9900\n",
      "Val Loss: 0.3463 Acc: 0.8829\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "Train Loss: 0.1111 Acc: 0.9900\n",
      "Val Loss: 0.3462 Acc: 0.8834\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.884024\n",
      "classes:  (0, 1, 2, 3, 4)\n",
      "Epoch 0/19\n",
      "----------\n",
      "Train Loss: 2.2024 Acc: 0.5040\n",
      "Val Loss: 1.0234 Acc: 0.6365\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "Train Loss: 0.6897 Acc: 0.7920\n",
      "Val Loss: 0.7309 Acc: 0.7651\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "Train Loss: 0.4916 Acc: 0.8800\n",
      "Val Loss: 0.5731 Acc: 0.7844\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "Train Loss: 0.3363 Acc: 0.9120\n",
      "Val Loss: 0.6452 Acc: 0.7470\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "Train Loss: 0.2508 Acc: 0.9120\n",
      "Val Loss: 0.4225 Acc: 0.8441\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "Train Loss: 0.2337 Acc: 0.9040\n",
      "Val Loss: 0.4243 Acc: 0.8484\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "Train Loss: 0.1924 Acc: 0.9440\n",
      "Val Loss: 0.3162 Acc: 0.8895\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "Train Loss: 0.1577 Acc: 0.9360\n",
      "Val Loss: 0.2916 Acc: 0.9136\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "Train Loss: 0.1228 Acc: 0.9760\n",
      "Val Loss: 0.2805 Acc: 0.9148\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "Train Loss: 0.1000 Acc: 0.9760\n",
      "Val Loss: 0.2920 Acc: 0.9056\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "Train Loss: 0.0944 Acc: 0.9760\n",
      "Val Loss: 0.2905 Acc: 0.9043\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "Train Loss: 0.0919 Acc: 0.9760\n",
      "Val Loss: 0.2856 Acc: 0.9066\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "Train Loss: 0.0902 Acc: 0.9760\n",
      "Val Loss: 0.2888 Acc: 0.9064\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "Train Loss: 0.0908 Acc: 0.9760\n",
      "Val Loss: 0.2896 Acc: 0.9056\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "Train Loss: 0.0869 Acc: 0.9840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2861 Acc: 0.9070\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "Train Loss: 0.0841 Acc: 0.9840\n",
      "Val Loss: 0.2855 Acc: 0.9074\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "Train Loss: 0.0840 Acc: 0.9840\n",
      "Val Loss: 0.2853 Acc: 0.9078\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "Train Loss: 0.0842 Acc: 0.9840\n",
      "Val Loss: 0.2861 Acc: 0.9076\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "Train Loss: 0.0838 Acc: 0.9840\n",
      "Val Loss: 0.2860 Acc: 0.9078\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "Train Loss: 0.0836 Acc: 0.9840\n",
      "Val Loss: 0.2856 Acc: 0.9082\n",
      "\n",
      "Training complete in 0m 12s\n",
      "Best val Acc: 0.914769\n",
      "classes:  (0, 1, 2, 3, 4)\n",
      "Epoch 0/19\n",
      "----------\n",
      "Train Loss: 1.9168 Acc: 0.5200\n",
      "Val Loss: 0.8761 Acc: 0.7449\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "Train Loss: 0.6532 Acc: 0.8267\n",
      "Val Loss: 0.6316 Acc: 0.7900\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "Train Loss: 0.4231 Acc: 0.8800\n",
      "Val Loss: 0.5184 Acc: 0.8072\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "Train Loss: 0.3238 Acc: 0.9067\n",
      "Val Loss: 0.3941 Acc: 0.8648\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "Train Loss: 0.2842 Acc: 0.8933\n",
      "Val Loss: 0.3629 Acc: 0.8854\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "Train Loss: 0.2131 Acc: 0.9400\n",
      "Val Loss: 0.3301 Acc: 0.8918\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "Train Loss: 0.1852 Acc: 0.9267\n",
      "Val Loss: 0.2576 Acc: 0.9204\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "Train Loss: 0.1558 Acc: 0.9267\n",
      "Val Loss: 0.2481 Acc: 0.9206\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "Train Loss: 0.1121 Acc: 0.9533\n",
      "Val Loss: 0.2406 Acc: 0.9226\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "Train Loss: 0.0984 Acc: 0.9733\n",
      "Val Loss: 0.2465 Acc: 0.9212\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "Train Loss: 0.0927 Acc: 0.9800\n",
      "Val Loss: 0.2509 Acc: 0.9202\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "Train Loss: 0.0890 Acc: 0.9867\n",
      "Val Loss: 0.2426 Acc: 0.9222\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "Train Loss: 0.0901 Acc: 0.9800\n",
      "Val Loss: 0.2487 Acc: 0.9204\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "Train Loss: 0.0866 Acc: 0.9867\n",
      "Val Loss: 0.2458 Acc: 0.9200\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "Train Loss: 0.0838 Acc: 0.9867\n",
      "Val Loss: 0.2491 Acc: 0.9208\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "Train Loss: 0.0817 Acc: 0.9867\n",
      "Val Loss: 0.2483 Acc: 0.9208\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "Train Loss: 0.0814 Acc: 0.9867\n",
      "Val Loss: 0.2482 Acc: 0.9210\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "Train Loss: 0.0812 Acc: 0.9867\n",
      "Val Loss: 0.2474 Acc: 0.9216\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "Train Loss: 0.0811 Acc: 0.9867\n",
      "Val Loss: 0.2475 Acc: 0.9216\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "Train Loss: 0.0810 Acc: 0.9867\n",
      "Val Loss: 0.2467 Acc: 0.9208\n",
      "\n",
      "Training complete in 0m 12s\n",
      "Best val Acc: 0.922553\n"
     ]
    }
   ],
   "source": [
    "shot_list = [5, 10, 15, 20, 25, 30] # no of images per class \n",
    "n_epochs = 20\n",
    "best_net_dict = {}\n",
    "best_acc_list = []\n",
    "for shot in shot_list:\n",
    "    \n",
    "    mninst_dataset = MNIST_Dataset(root='data/', normal_class=[0,1,2,3,4], shots=shot)\n",
    "    train_loader = DataLoader(mninst_dataset.train_set, batch_size=5, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(mninst_dataset.test_set, batch_size=200, shuffle=True, num_workers=0)\n",
    "    train_size =  len(mninst_dataset.train_set)\n",
    "    test_size = len(mninst_dataset.test_set)\n",
    "    \n",
    "#     net = LeNet().to(device)\n",
    "# loading pretrained model\n",
    "    net = torch.load('LeNet_5_class_pretrained_model.tar')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "    best_net, best_acc = train_model(net, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                           num_epochs=n_epochs)\n",
    "    \n",
    "    best_acc_list.append(best_acc.item())\n",
    "    best_net_dict.update({shot : best_net})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 class LeNet model is trained for [5,6,7,8,9] classes and accuracy acheived 0.916, this model is taken as pretrained model.\n",
    "\n",
    "Pretrained model is trained using differente shots [5 -30] for classes [0,1,2,3,4] for 20 epochs and following results acheived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model Acc: 0.916067\n",
      "5 way N shots classification accuracy using LeNet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># images per class</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.734190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.817474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.883830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.884024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.914769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>0.922553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # images per class  Accuracy\n",
       "0                   5  0.734190\n",
       "1                  10  0.817474\n",
       "2                  15  0.883830\n",
       "3                  20  0.884024\n",
       "4                  25  0.914769\n",
       "5                  30  0.922553"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Pretrained model Acc: 0.916067\")\n",
    "print(\"5 way N shots classification accuracy using LeNet\")\n",
    "best_acc_df = pd.DataFrame({'# images per class' : shot_list,\n",
    "                            'Accuracy' : best_acc_list})\n",
    "best_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
